{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c9219e",
   "metadata": {},
   "source": [
    "# ðŸ§  Air Pollution ML Preprocessing: From Raw to Ready (Baby Style)\n",
    "This notebook walks you through **every step** of preparing air pollution data for ML modeling.\n",
    "\n",
    "We'll answer:\n",
    "- Why are there only 2 dots?\n",
    "- What does interpolation mean?\n",
    "- What is 2km Ã— 2km?\n",
    "- How to convert the real-world map into ML-ready 2D arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45125e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Path where your .parquet files are stored (edit this if needed)\n",
    "folder_path = \"C:/Users/elhajjas/Downloads/ParquetFiles/E1a\"  # Same folder as notebook\n",
    "parquet_files = glob.glob(os.path.join(folder_path, \"*.parquet\"))\n",
    "print(f\"Found {len(parquet_files)} parquet files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b6368f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Samplingpoint', 'Pollutant', 'Start', 'End', 'Value', 'Unit',\n",
      "       'AggType', 'Validity', 'Verification', 'ResultTime', 'DataCapture',\n",
      "       'FkObservationLog'],\n",
      "      dtype='object')\n",
      "              Samplingpoint  Pollutant               Start  \\\n",
      "0  LU/SPO-LU0101A_00008_101          8 2022-08-31 00:00:00   \n",
      "1  LU/SPO-LU0101A_00008_101          8 2022-08-31 01:00:00   \n",
      "2  LU/SPO-LU0101A_00008_101          8 2022-08-31 02:00:00   \n",
      "3  LU/SPO-LU0101A_00008_101          8 2022-08-31 03:00:00   \n",
      "4  LU/SPO-LU0101A_00008_101          8 2022-08-31 04:00:00   \n",
      "\n",
      "                  End                    Value    Unit AggType  Validity  \\\n",
      "0 2022-08-31 01:00:00    17.400000000000000000  ug.m-3    hour         1   \n",
      "1 2022-08-31 02:00:00    13.200000000000000000  ug.m-3    hour         1   \n",
      "2 2022-08-31 03:00:00  -999.000000000000000000  ug.m-3    hour        -1   \n",
      "3 2022-08-31 04:00:00     9.700000000000000000  ug.m-3    hour         1   \n",
      "4 2022-08-31 05:00:00    16.100000000000000000  ug.m-3    hour         1   \n",
      "\n",
      "   Verification          ResultTime DataCapture  \\\n",
      "0             1 2023-09-21 08:59:34        None   \n",
      "1             1 2023-09-21 08:59:34        None   \n",
      "2             1 2023-09-21 08:59:34        None   \n",
      "3             1 2023-09-21 08:59:34        None   \n",
      "4             1 2023-09-21 08:59:34        None   \n",
      "\n",
      "                       FkObservationLog  \n",
      "0  dc8ce238-5ff3-43f2-bd86-d31e68e6b726  \n",
      "1  dc8ce238-5ff3-43f2-bd86-d31e68e6b726  \n",
      "2  dc8ce238-5ff3-43f2-bd86-d31e68e6b726  \n",
      "3  dc8ce238-5ff3-43f2-bd86-d31e68e6b726  \n",
      "4  dc8ce238-5ff3-43f2-bd86-d31e68e6b726  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load all parquet files into a single DataFrame\n",
    "df_list = [pd.read_parquet(file) for file in parquet_files]\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Preview data\n",
    "print(df.columns)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03690b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7768de52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Country', 'B-G Namespace', 'Year', 'Air Quality Network',\n",
      "       'Air Quality Network Name', 'Timezone', 'Air Quality Station EoI Code',\n",
      "       'Air Quality Station Nat Code', 'Air Quality Station Name',\n",
      "       'Samplingpoint', 'Air Pollutant', 'Longitude', 'Latitude', 'Altitude',\n",
      "       'Altitude Unit', 'Air Quality Station Area', 'Air Quality Station Type',\n",
      "       'Operational Activity Begin', 'Operational Activity End', 'Sample Id',\n",
      "       'Inlet Height', 'Inlet Height Unit', 'Building Distance',\n",
      "       'Building Distance Unit', 'Kerb Distance', 'Kerb Distance Unit',\n",
      "       'Distance Source', 'Distance Source Unit', 'Main Emission Sources',\n",
      "       'Heating Emissions', 'Heating Emissions Unit', 'Mobile',\n",
      "       'Traffic Emissions', 'Traffic Emissions Unit', 'Industrial Emissions',\n",
      "       'Industrial Emissions Unit', 'Municipality', 'Dispersion Local',\n",
      "       'Dispersion Regional', 'Distance Junction', 'Distance Junction Unit',\n",
      "       'Heavy Duty Fraction', 'Height Facades', 'Street Width',\n",
      "       'Traffic Speed', 'Traffic Volume', 'Process Id',\n",
      "       'Process Activity Begin', 'Process Activity End', 'Measurement Type',\n",
      "       'Measurement Method', 'Other Measurement Method',\n",
      "       'Measurement Equipment', 'Other Measurement Equipment',\n",
      "       'Sampling Method', 'Other Sampling Method', 'Analytical Technique',\n",
      "       'Other Analytical Technique', 'Equivalence Demonstrated',\n",
      "       'Demonstration Report', 'Detection Limit', 'Detection Limit Unit',\n",
      "       'Documentation', 'QA Report', 'Duration', 'Duration Unit', 'Cadence',\n",
      "       'Cadence Unit', 'Source Data URL', 'Imported'],\n",
      "      dtype='object')\n",
      "      Country          B-G Namespace  Year Air Quality Network  \\\n",
      "0  Luxembourg  LU.AdmEnv_AirBruit.AQ  2024          NET-LU006A   \n",
      "1  Luxembourg  LU.AdmEnv_AirBruit.AQ  2024          NET-LU006A   \n",
      "2  Luxembourg  LU.AdmEnv_AirBruit.AQ  2024          NET-LU006A   \n",
      "3  Luxembourg  LU.AdmEnv_AirBruit.AQ  2024          NET-LU006A   \n",
      "4  Luxembourg  LU.AdmEnv_AirBruit.AQ  2024          NET-LU006A   \n",
      "\n",
      "                   Air Quality Network Name Timezone  \\\n",
      "0  NO2 passive sampler network - Luxembourg      UTC   \n",
      "1  NO2 passive sampler network - Luxembourg      UTC   \n",
      "2  NO2 passive sampler network - Luxembourg      UTC   \n",
      "3  NO2 passive sampler network - Luxembourg      UTC   \n",
      "4  NO2 passive sampler network - Luxembourg      UTC   \n",
      "\n",
      "  Air Quality Station EoI Code Air Quality Station Nat Code  \\\n",
      "0                      LU0765P                      NMAER05   \n",
      "1                      LU0766P                      NMECH01   \n",
      "2                      LU0767P                      NMECH02   \n",
      "3                      LU0768P                      NMECH03   \n",
      "4                      LU0772P                      NWAIG04   \n",
      "\n",
      "                 Air Quality Station Name          Samplingpoint  ...  \\\n",
      "0                 Mamer - rue du Commerce  SPO-LU0765P_00008_100  ...   \n",
      "1  Mersch - rue Grande-Duchesse Charlotte  SPO-LU0766P_00008_100  ...   \n",
      "2                Mersch - rue de Beringen  SPO-LU0767P_00008_100  ...   \n",
      "3                 Mersch - rue Agrocentre  SPO-LU0768P_00008_100  ...   \n",
      "4      Wasserbillig - route de Luxembourg  SPO-LU0772P_00008_100  ...   \n",
      "\n",
      "  Detection Limit  Detection Limit Unit  Documentation           QA Report  \\\n",
      "0             NaN                   NaN            NaN  http://missing.com   \n",
      "1             NaN                   NaN            NaN  http://missing.com   \n",
      "2             NaN                   NaN            NaN  http://missing.com   \n",
      "3             NaN                   NaN            NaN  http://missing.com   \n",
      "4             NaN                   NaN            NaN  http://missing.com   \n",
      "\n",
      "  Duration Duration Unit Cadence Cadence Unit  \\\n",
      "0        2          week       2         week   \n",
      "1        2          week       2         week   \n",
      "2        2          week       2         week   \n",
      "3        2          week       2         week   \n",
      "4        2          week       2         week   \n",
      "\n",
      "                                     Source Data URL       Imported  \n",
      "0  http://cdr.eionet.europa.eu/lu/eu/aqd/d/envz_o...  5/4/2025 2:00  \n",
      "1  http://cdr.eionet.europa.eu/lu/eu/aqd/d/envz_o...  5/4/2025 2:00  \n",
      "2  http://cdr.eionet.europa.eu/lu/eu/aqd/d/envz_o...  5/4/2025 2:00  \n",
      "3  http://cdr.eionet.europa.eu/lu/eu/aqd/d/envz_o...  5/4/2025 2:00  \n",
      "4  http://cdr.eionet.europa.eu/lu/eu/aqd/d/envz_o...  5/4/2025 2:00  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the lookup table\n",
    "stations_df = pd.read_csv(\"C:/Users/elhajjas/Downloads/DataExtract.csv/DataExtract.csv\")\n",
    "\n",
    "# Preview\n",
    "print(stations_df.columns)\n",
    "print(stations_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c5578a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example (adjust based on actual names)\n",
    "stations_df = stations_df.rename(columns={\n",
    "    \"Latitude\": \"latitude\",\n",
    "    \"Longitude\": \"longitude\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "459cdaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge coordinates into main NO2 data\n",
    "df = df.merge(stations_df, on=\"Samplingpoint\", how=\"left\")\n",
    "\n",
    "# # Drop invalid or missing geolocations\n",
    "# df = df.dropna(subset=[\"latitude\", \"longitude\", \"Value\"])  # 'Value' is your NO2 reading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd4c82d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Samplingpoint</th>\n",
       "      <th>Pollutant</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Value</th>\n",
       "      <th>Unit</th>\n",
       "      <th>AggType</th>\n",
       "      <th>Validity</th>\n",
       "      <th>Verification</th>\n",
       "      <th>ResultTime</th>\n",
       "      <th>...</th>\n",
       "      <th>Detection Limit_y</th>\n",
       "      <th>Detection Limit Unit_y</th>\n",
       "      <th>Documentation_y</th>\n",
       "      <th>QA Report_y</th>\n",
       "      <th>Duration_y</th>\n",
       "      <th>Duration Unit_y</th>\n",
       "      <th>Cadence_y</th>\n",
       "      <th>Cadence Unit_y</th>\n",
       "      <th>Source Data URL_y</th>\n",
       "      <th>Imported_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LU/SPO-LU0101A_00008_101</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-08-31 00:00:00</td>\n",
       "      <td>2022-08-31 01:00:00</td>\n",
       "      <td>17.4</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>hour</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-09-21 08:59:34</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LU/SPO-LU0101A_00008_101</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-08-31 01:00:00</td>\n",
       "      <td>2022-08-31 02:00:00</td>\n",
       "      <td>13.2</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>hour</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-09-21 08:59:34</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LU/SPO-LU0101A_00008_101</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-08-31 02:00:00</td>\n",
       "      <td>2022-08-31 03:00:00</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>hour</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-09-21 08:59:34</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LU/SPO-LU0101A_00008_101</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-08-31 03:00:00</td>\n",
       "      <td>2022-08-31 04:00:00</td>\n",
       "      <td>9.7</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>hour</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-09-21 08:59:34</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LU/SPO-LU0101A_00008_101</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-08-31 04:00:00</td>\n",
       "      <td>2022-08-31 05:00:00</td>\n",
       "      <td>16.1</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>hour</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-09-21 08:59:34</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35134</th>\n",
       "      <td>LU/SPO-LU0114A_00008_100</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>5.3</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>hour</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-05 07:00:19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35135</th>\n",
       "      <td>LU/SPO-LU0114A_00008_100</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>hour</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-05 07:00:19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35136</th>\n",
       "      <td>LU/SPO-LU0114A_00008_100</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>hour</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-05 07:00:19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35137</th>\n",
       "      <td>LU/SPO-LU0114A_00008_100</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>hour</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-05 07:00:19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35138</th>\n",
       "      <td>LU/SPO-LU0114A_00008_100</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>hour</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-05 07:00:19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35139 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Samplingpoint  Pollutant               Start  \\\n",
       "0      LU/SPO-LU0101A_00008_101          8 2022-08-31 00:00:00   \n",
       "1      LU/SPO-LU0101A_00008_101          8 2022-08-31 01:00:00   \n",
       "2      LU/SPO-LU0101A_00008_101          8 2022-08-31 02:00:00   \n",
       "3      LU/SPO-LU0101A_00008_101          8 2022-08-31 03:00:00   \n",
       "4      LU/SPO-LU0101A_00008_101          8 2022-08-31 04:00:00   \n",
       "...                         ...        ...                 ...   \n",
       "35134  LU/SPO-LU0114A_00008_100          8 2023-12-31 20:00:00   \n",
       "35135  LU/SPO-LU0114A_00008_100          8 2023-12-31 21:00:00   \n",
       "35136  LU/SPO-LU0114A_00008_100          8 2023-12-31 22:00:00   \n",
       "35137  LU/SPO-LU0114A_00008_100          8 2023-12-31 23:00:00   \n",
       "35138  LU/SPO-LU0114A_00008_100          8 2024-01-01 00:00:00   \n",
       "\n",
       "                      End  Value    Unit AggType  Validity  Verification  \\\n",
       "0     2022-08-31 01:00:00   17.4  ug.m-3    hour         1             1   \n",
       "1     2022-08-31 02:00:00   13.2  ug.m-3    hour         1             1   \n",
       "2     2022-08-31 03:00:00 -999.0  ug.m-3    hour        -1             1   \n",
       "3     2022-08-31 04:00:00    9.7  ug.m-3    hour         1             1   \n",
       "4     2022-08-31 05:00:00   16.1  ug.m-3    hour         1             1   \n",
       "...                   ...    ...     ...     ...       ...           ...   \n",
       "35134 2023-12-31 21:00:00    5.3  ug.m-3    hour         1             1   \n",
       "35135 2023-12-31 22:00:00    2.7  ug.m-3    hour         1             1   \n",
       "35136 2023-12-31 23:00:00    2.5  ug.m-3    hour         1             1   \n",
       "35137 2024-01-01 00:00:00    2.0  ug.m-3    hour         1             1   \n",
       "35138 2024-01-01 01:00:00    1.9  ug.m-3    hour         1             1   \n",
       "\n",
       "               ResultTime  ... Detection Limit_y Detection Limit Unit_y  \\\n",
       "0     2023-09-21 08:59:34  ...               NaN                    NaN   \n",
       "1     2023-09-21 08:59:34  ...               NaN                    NaN   \n",
       "2     2023-09-21 08:59:34  ...               NaN                    NaN   \n",
       "3     2023-09-21 08:59:34  ...               NaN                    NaN   \n",
       "4     2023-09-21 08:59:34  ...               NaN                    NaN   \n",
       "...                   ...  ...               ...                    ...   \n",
       "35134 2024-09-05 07:00:19  ...               NaN                    NaN   \n",
       "35135 2024-09-05 07:00:19  ...               NaN                    NaN   \n",
       "35136 2024-09-05 07:00:19  ...               NaN                    NaN   \n",
       "35137 2024-09-05 07:00:19  ...               NaN                    NaN   \n",
       "35138 2024-09-05 07:00:19  ...               NaN                    NaN   \n",
       "\n",
       "      Documentation_y QA Report_y  Duration_y Duration Unit_y Cadence_y  \\\n",
       "0                 NaN         NaN         NaN             NaN       NaN   \n",
       "1                 NaN         NaN         NaN             NaN       NaN   \n",
       "2                 NaN         NaN         NaN             NaN       NaN   \n",
       "3                 NaN         NaN         NaN             NaN       NaN   \n",
       "4                 NaN         NaN         NaN             NaN       NaN   \n",
       "...               ...         ...         ...             ...       ...   \n",
       "35134             NaN         NaN         NaN             NaN       NaN   \n",
       "35135             NaN         NaN         NaN             NaN       NaN   \n",
       "35136             NaN         NaN         NaN             NaN       NaN   \n",
       "35137             NaN         NaN         NaN             NaN       NaN   \n",
       "35138             NaN         NaN         NaN             NaN       NaN   \n",
       "\n",
       "      Cadence Unit_y Source Data URL_y Imported_y  \n",
       "0                NaN               NaN        NaN  \n",
       "1                NaN               NaN        NaN  \n",
       "2                NaN               NaN        NaN  \n",
       "3                NaN               NaN        NaN  \n",
       "4                NaN               NaN        NaN  \n",
       "...              ...               ...        ...  \n",
       "35134            NaN               NaN        NaN  \n",
       "35135            NaN               NaN        NaN  \n",
       "35136            NaN               NaN        NaN  \n",
       "35137            NaN               NaN        NaN  \n",
       "35138            NaN               NaN        NaN  \n",
       "\n",
       "[35139 rows x 150 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdaaf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb784089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude     35139\n",
      "longitude    35139\n",
      "dtype: int64\n",
      "Samplingpoint              object\n",
      "Pollutant                   int32\n",
      "Start              datetime64[ns]\n",
      "End                datetime64[ns]\n",
      "Value                      object\n",
      "                        ...      \n",
      "Duration Unit              object\n",
      "Cadence                   float64\n",
      "Cadence Unit               object\n",
      "Source Data URL            object\n",
      "Imported                   object\n",
      "Length: 81, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[['latitude', 'longitude']].isna().sum())\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e42f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Value column to numeric NO2 concentrations\n",
    "df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n",
    "\n",
    "# Drop any rows with missing coordinates or NO2 values\n",
    "df_clean = df.dropna(subset=['latitude', 'longitude', 'Value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d56f5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [latitude, longitude, Value]\n",
      "Index: []\n",
      "Rows remaining: 0\n"
     ]
    }
   ],
   "source": [
    "print(df_clean[['latitude', 'longitude', 'Value']].head())\n",
    "print(\"Rows remaining:\", len(df_clean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c33a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.dropna(subset=['latitude', 'longitude', 'Value'])  # ensure no NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16494dc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Location values cannot contain NaNs.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create base map centered on mean location\u001b[39;00m\n\u001b[0;32m      5\u001b[0m map_center \u001b[38;5;241m=\u001b[39m [df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(), df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()]\n\u001b[1;32m----> 6\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mfolium\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_center\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create heatmap layer using NO2 concentration as weight\u001b[39;00m\n\u001b[0;32m      9\u001b[0m heat_data \u001b[38;5;241m=\u001b[39m [[row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNO2\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows()]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\folium\\folium.py:300\u001b[0m, in \u001b[0;36mMap.__init__\u001b[1;34m(self, location, width, height, left, top, position, tiles, attr, min_zoom, max_zoom, zoom_start, min_lat, max_lat, min_lon, max_lon, max_bounds, crs, control_scale, prefer_canvas, no_touch, disable_3d, png_enabled, zoom_control, font_size, **kwargs)\u001b[0m\n\u001b[0;32m    298\u001b[0m     zoom_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m Figure()\u001b[38;5;241m.\u001b[39madd_child(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# Map Size Parameters.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\folium\\utilities.py:110\u001b[0m, in \u001b[0;36mvalidate_location\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation should consist of two numerical values, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoord\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(coord)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not convertible to float.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m         )\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m math\u001b[38;5;241m.\u001b[39misnan(\u001b[38;5;28mfloat\u001b[39m(coord)):\n\u001b[1;32m--> 110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation values cannot contain NaNs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m coords]\n",
      "\u001b[1;31mValueError\u001b[0m: Location values cannot contain NaNs."
     ]
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Create base map centered on mean location\n",
    "map_center = [df['latitude'].mean(), df['longitude'].mean()]\n",
    "m = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Create heatmap layer using NO2 concentration as weight\n",
    "heat_data = [[row['latitude'], row['longitude'], row['NO2']] for index, row in df.iterrows()]\n",
    "HeatMap(heat_data, radius=8, blur=5).add_to(m)\n",
    "\n",
    "# Save or display\n",
    "m.save(\"NO2_map.html\")\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47c10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sc = plt.scatter(df['longitude'], df['latitude'], c=df['NO2'], cmap='inferno', s=10)\n",
    "plt.colorbar(sc, label='NOâ‚‚ concentration')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('NOâ‚‚ Concentration Map')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55359b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all .parquet files into one DataFrame\n",
    "dfs = []\n",
    "for f in parquet_files:\n",
    "    df = pd.read_parquet(f)\n",
    "    df['source_file'] = os.path.basename(f)\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884dfeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show info and example column names\n",
    "combined_df.info()\n",
    "print(\"Columns:\", combined_df.columns.tolist())\n",
    "combined_df[['Start', 'End', 'Pollutant', 'Samplingpoint', 'Value']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b746426",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"Pollutant\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60379891",
   "metadata": {},
   "outputs": [],
   "source": [
    "pollutant_map = {6001: \"PM10\", 5: \"PM2.5\"}\n",
    "combined_df[\"PollutantName\"] = combined_df[\"Pollutant\"].map(pollutant_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata CSV\n",
    "metadata = pd.read_csv(\"C:/Users/elhajjas/Downloads/DataExtract.csv/DataExtract.csv\")\n",
    "\n",
    "# Clean and rename columns\n",
    "metadata.columns = metadata.columns.str.strip()\n",
    "metadata = metadata.rename(columns={\"Sampling Point Id\": \"Samplingpoint\"})\n",
    "\n",
    "# Keep only relevant columns\n",
    "metadata = metadata[[\"Samplingpoint\", \"Latitude\", \"Longitude\"]]\n",
    "\n",
    "# Drop duplicates (in case the same Samplingpoint has multiple pollutants)\n",
    "metadata = metadata.drop_duplicates(subset=[\"Samplingpoint\"])\n",
    "\n",
    "# Merge with your measurement data\n",
    "combined_df = combined_df.merge(metadata, on=\"Samplingpoint\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fcbc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"PollutantName\"] = combined_df[\"Pollutant\"].map(pollutant_map)\n",
    "combined_df[\"Start\"] = pd.to_datetime(combined_df[\"Start\"])\n",
    "combined_df[\"StartHour\"] = combined_df[\"Start\"].dt.floor(\"H\")\n",
    "combined_df[\"Samplingpoint\"] = combined_df[\"Samplingpoint\"].str.replace(\"LU/\", \"\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c165479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned measurement data (CSV format)\n",
    "measurements = combined_df\n",
    "meta = pd.read_csv(\"C:/Users/elhajjas/Downloads/DataExtract.csv/DataExtract.csv\")\n",
    "\n",
    "# Clean Samplingpoint ID (match format on both sides)\n",
    "# Load station metadata (one row per Samplingpoint)\n",
    "meta = pd.read_csv(\"C:/Users/elhajjas/Downloads/DataExtract.csv/DataExtract.csv\")\n",
    "meta.columns = meta.columns.str.strip()\n",
    "meta = meta.rename(columns={\"Sampling Point Id\": \"Samplingpoint\"})\n",
    "meta = meta[[\"Samplingpoint\", \"Latitude\", \"Longitude\"]].drop_duplicates()\n",
    "# Final Samplingpoint cleanup\n",
    "# Clean Samplingpoint on both sides\n",
    "combined_df[\"Samplingpoint\"] = combined_df[\"Samplingpoint\"].str.upper().str.strip().str.replace(\"LU/\", \"\", regex=False)\n",
    "meta[\"Samplingpoint\"] = meta[\"Samplingpoint\"].str.upper().str.strip()\n",
    "\n",
    "# Merge metadata (Latitude, Longitude)\n",
    "df = measurements.merge(meta[[\"Samplingpoint\", \"Latitude\", \"Longitude\"]], on=\"Samplingpoint\", how=\"left\")\n",
    "\n",
    "# Map pollutant codes to names\n",
    "pollutant_map = {5: \"PM2.5\", 6001: \"PM10\"}\n",
    "df[\"PollutantName\"] = df[\"Pollutant\"].map(pollutant_map)\n",
    "\n",
    "# Parse datetime\n",
    "df[\"Start\"] = pd.to_datetime(df[\"Start\"])\n",
    "df[\"Hour\"] = df[\"Start\"].dt.floor(\"H\")\n",
    "\n",
    "# Drop missing coordinates\n",
    "df = df.dropna(subset=[\"Latitude\", \"Longitude\", \"Value\"])\n",
    "print(f\"After merge: {df.shape[0]} rows, {df['Samplingpoint'].nunique()} stations\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "station_count = df.groupby(\"Hour\")[\"Samplingpoint\"].nunique()\n",
    "plt.figure(figsize=(10, 4))\n",
    "station_count.plot()\n",
    "plt.title(\"ðŸ›° Number of Stations Available per Hour\")\n",
    "plt.ylabel(\"Number of Stations\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2501fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find first hour with at least 2 stations\n",
    "valid_hours = station_count[station_count >= 2].index\n",
    "example_time = valid_hours[0]\n",
    "print(\"Selected hour:\", example_time)\n",
    "\n",
    "df_hour = df[(df[\"Hour\"] == example_time) & (df[\"PollutantName\"] == \"PM2.5\")]\n",
    "df_hour = df_hour.dropna(subset=[\"Latitude\", \"Longitude\", \"Value\"])\n",
    "print(f\"Stations used: {len(df_hour)}\")\n",
    "df_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72de8315",
   "metadata": {},
   "source": [
    "## ðŸŽ¨ What is Interpolation (Baby Style)\n",
    "\n",
    "Imagine you only have **2 weather stations** that tell you the air pollution.\n",
    "\n",
    "But your ML model needs a **grid** like pixels in an image.\n",
    "\n",
    "So we use a trick called **Inverse Distance Weighting (IDW)**:\n",
    "- Pretend pollution spreads out from each station\n",
    "- Areas **closer to a station** get more influence\n",
    "- We \"guess\" the pollution at each pixel (grid cell) based on the nearest stations\n",
    "\n",
    "The more stations you have, the better your guess ðŸ’¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91567044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def idw(x, y, z, xi, yi, power=2):\n",
    "    tree = cKDTree(np.c_[x, y])\n",
    "    k = min(4, len(z))\n",
    "    dist, idx = tree.query(np.c_[xi.ravel(), yi.ravel()], k=k)\n",
    "    if k == 1:\n",
    "        idx = idx[:, np.newaxis]\n",
    "        dist = dist[:, np.newaxis]\n",
    "    weights = 1 / (dist**power + 1e-12)\n",
    "    weights /= weights.sum(axis=1)[:, None]\n",
    "    zi = np.sum(weights * z[idx], axis=1)\n",
    "    return zi.reshape(xi.shape)\n",
    "\n",
    "# Create grid from min/max lat/lon\n",
    "lon_min, lon_max = df_hour[\"Longitude\"].min(), df_hour[\"Longitude\"].max()\n",
    "lat_min, lat_max = df_hour[\"Latitude\"].min(), df_hour[\"Latitude\"].max()\n",
    "grid_x = np.linspace(lon_min, lon_max, 100)\n",
    "grid_y = np.linspace(lat_min, lat_max, 100)\n",
    "xi, yi = np.meshgrid(grid_x, grid_y)\n",
    "\n",
    "# Interpolate\n",
    "x, y, z = df_hour[\"Longitude\"].values, df_hour[\"Latitude\"].values, df_hour[\"Value\"].values\n",
    "zi = idw(x, y, z, xi, yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "cs = plt.contourf(xi, yi, zi, cmap=\"plasma\", levels=20)\n",
    "plt.scatter(x, y, c=z, cmap=\"plasma\", edgecolor=\"white\", s=100, label=\"Stations\")\n",
    "plt.colorbar(cs, label=\"PM2.5 (Âµg/mÂ³)\")\n",
    "plt.title(f\"ðŸ—º Interpolated PM2.5 Field @ {example_time}\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8493d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final ML input: 100x100 pixel grid of pollution\n",
    "ml_input = zi.astype(np.float32)\n",
    "print(\"ML input shape:\", ml_input.shape)\n",
    "\n",
    "# Save for model\n",
    "np.save(\"pm25_grid_input.npy\", ml_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
